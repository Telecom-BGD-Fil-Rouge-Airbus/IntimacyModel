{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4J_HRJznf84"
      },
      "source": [
        "# Install and import necessary modules"
      ],
      "id": "Q4J_HRJznf84"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1ocLY-slqpx",
        "outputId": "05868737-f316-4b3b-aefc-17fc03319b7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.7/250.7 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m118.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m114.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.7/206.7 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install simpletransformers --quiet"
      ],
      "id": "a1ocLY-slqpx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NE9oAdDnibdm"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pickle\n",
        "import logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "import torch\n",
        "from simpletransformers.classification import ClassificationModel, ClassificationArgs"
      ],
      "id": "NE9oAdDnibdm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUnrhTsonoBl"
      },
      "source": [
        "## Connection to colab"
      ],
      "id": "rUnrhTsonoBl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNSDepRpIgRz"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd \"/content/drive/MyDrive/Telecom/Airbus/Intimacy\""
      ],
      "id": "HNSDepRpIgRz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsPAZbBVioWD"
      },
      "source": [
        "## Set seed and logger"
      ],
      "id": "OsPAZbBVioWD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXyH_a0uipc0"
      },
      "outputs": [],
      "source": [
        "seed = 56\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)"
      ],
      "id": "HXyH_a0uipc0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qbfp3Ebyir-V"
      },
      "source": [
        "# Load data"
      ],
      "id": "Qbfp3Ebyir-V"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhttQVUYitVJ"
      },
      "outputs": [],
      "source": [
        "# Read train data\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "df = df.sample(frac=1, random_state=0)\n",
        "train_texts = list(df.text.values)\n",
        "train_labels = list(df.label.values)\n",
        "\n",
        "# Read translated train data\n",
        "with open('translated_train.pickle', 'rb') as f:\n",
        "    tr_train_texts = pickle.load(f)"
      ],
      "id": "YhttQVUYitVJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5gxy0GAizsH"
      },
      "source": [
        "# Pre-processing"
      ],
      "id": "O5gxy0GAizsH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVDwJOhci2tG"
      },
      "outputs": [],
      "source": [
        "# Combine original and translated train texts\n",
        "train_texts = [train_texts[i] + ' </s></s> ' + tr_train_texts[i] for i in range(len(train_texts))]\n",
        "\n",
        "# Create train_df from combined train texts and labels\n",
        "train_df = pd.DataFrame({\"text\": train_texts, \"labels\": train_labels})\n",
        "\n",
        "# Split train_df into train, val, and test sets\n",
        "train_df, test_df = train_test_split(train_df, test_size=0.2, random_state=0)"
      ],
      "id": "EVDwJOhci2tG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgJWYPu-jEnE"
      },
      "source": [
        "# Initialize model"
      ],
      "id": "xgJWYPu-jEnE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyhtPeHKjIHm"
      },
      "outputs": [],
      "source": [
        "epochs = 4\n",
        "max_seq_length = 162\n",
        "use_cuda = True\n",
        "\n",
        "# Define model arguments\n",
        "model_args = ClassificationArgs(\n",
        "    num_train_epochs=epochs, overwrite_output_dir=True,\n",
        "    no_save=False, max_seq_length=max_seq_length, regression=True\n",
        ")\n",
        "\n",
        "# Initialize the model\n",
        "model = ClassificationModel(\n",
        "    \"xlmroberta\", \"cardiffnlp/twitter-xlm-roberta-base\", args=model_args, use_cuda=use_cuda, num_labels=1\n",
        ")\n",
        "\n",
        "# other possibilities\n",
        "#\"xlmroberta\", \"xlm-roberta-base\", args=model_args, use_cuda=True, num_labels=1\n",
        "#\"bert\", \"bert-base-multilingual-cased\", args=model_args, use_cuda=True, num_labels=1"
      ],
      "id": "RyhtPeHKjIHm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNMpxeWKjK8P"
      },
      "source": [
        "# Train and test the model"
      ],
      "id": "uNMpxeWKjK8P"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80eef1ec"
      },
      "outputs": [],
      "source": [
        "model.train_model(train_df)\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_texts = list(test_df[\"text\"].values)\n",
        "test_labels = list(test_df[\"labels\"].values)\n",
        "\n",
        "predictions, _ = model.predict(test_texts)\n",
        "r2 = r2_score(predictions, test_labels)\n",
        "print(f\"Test R2 Score: {r2}\")\n"
      ],
      "id": "80eef1ec"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cg0A89otuj5Y"
      },
      "outputs": [],
      "source": [
        "#access the hugging face model for saving\n",
        "model.model.save_pretrained('model_intimacy')\n",
        "model.tokenizer.save_pretrained('model_intimacy')\n",
        "model.config.save_pretrained('model_intimacy/')"
      ],
      "id": "cg0A89otuj5Y"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Q4J_HRJznf84",
        "Qbfp3Ebyir-V",
        "xgJWYPu-jEnE"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}